Modsel metrics to measure

𝟭. 𝗦𝗼𝗳𝘁𝘄𝗮𝗿𝗲 - 𝗰𝗼𝗺𝗽𝘂𝘁𝗲 𝗲𝗻𝗴𝗶𝗻𝗲 𝗮𝗻𝗱 𝗲𝗻𝘃𝗶𝗿𝗼𝗻𝗺𝗲𝗻𝘁 𝘂𝘀𝗲𝗱 𝘁𝗼 𝘀𝗲𝗿𝘃𝗲 𝘁𝗵𝗲 𝗺𝗼𝗱𝗲𝗹. 

The metrics tracked were memory usage, compute utilization and prediction latency. If there were ever errors or over-usage of resources, there were alerts set up to notify me and my team via email.

𝟮. 𝗠𝗼𝗱𝗲𝗹 𝗜𝗻𝗽𝘂𝘁 - 𝗾𝘂𝗮𝗹𝗶𝘁𝘆 𝗼𝗳 𝘁𝗵𝗲 𝗱𝗮𝘁𝗮 𝗶𝗻 𝘁𝗵𝗲 𝗱𝗼𝘄𝗻𝘀𝘁𝗿𝗲𝗮𝗺 𝗽𝗿𝗼𝗰𝗲𝘀𝘀. 

The metrics tracked were null rate, outliers, and trend shifts. If there were shifts and performance declined greatly, then it's important to consider re-designing the model

𝟯. 𝗠𝗼𝗱𝗲𝗹 𝗣𝗲𝗿𝗳𝗼𝗿𝗺𝗮𝗻𝗰𝗲 - 𝗼𝗻𝗹𝗶𝗻𝗲 𝗺𝗼𝗱𝗲𝗹 𝗽𝗲𝗿𝗳𝗼𝗿𝗺𝗮𝗻𝗰𝗲

It's not enough to achieve a high score on an offline dataset (that's Kaggle). What matters more is your model performs just as well in production.

Primarily there were two sets of metrics tracked in production that included the time-series CV scores of the MAPE, MPE, RMSE, and forecast variance.

𝟰. 𝗨𝘀𝗲𝗿 𝗜𝗻𝘁𝗲𝗿𝗮𝗰𝘁𝗶𝗼𝗻 - 𝘀𝗲𝘀𝘀𝗶𝗼𝗻 𝘁𝗶𝗺𝗲, 𝘁𝗿𝗲𝗻𝗱 𝘀𝗵𝗶𝗳𝘁

The final deliverable was in the form of a dashboard. At the end of the day, the model is designed to serve a user. It's vital to track the usage. From the dashboard, session time and trend shifts were tracked.
